{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89e6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk import WordNetLemmatizer\n",
    "import spacy\n",
    "import imblearn\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17ca85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eat shit\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJohn J Lavorato@ex...</td>\n",
       "      <td>Abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck you</td>\n",
       "      <td>Abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gentlemen:\\r\\nThe following champagne is avail...</td>\n",
       "      <td>Abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sorry i've taken so long...just been trying to...</td>\n",
       "      <td>Abusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asshole\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJohn J Lavorato@exc...</td>\n",
       "      <td>Abusive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content    Class\n",
       "0  eat shit\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJohn J Lavorato@ex...  Abusive\n",
       "1                                           fuck you  Abusive\n",
       "2  Gentlemen:\\r\\nThe following champagne is avail...  Abusive\n",
       "3  sorry i've taken so long...just been trying to...  Abusive\n",
       "4  asshole\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJohn J Lavorato@exc...  Abusive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('H:/ExcelR Data Science/Project P72/emails1_edit.txt')\n",
    "df.drop(['Unnamed: 0', 'filename', 'Message-ID'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e0434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "df.drop_duplicates(keep='first',inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70aed391",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = spacy.load('en_core_web_sm')\n",
    "sw_spacy = en.Defaults.stop_words\n",
    "adds= ['subject','image']\n",
    "sw_spacy.update(adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a779bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    # removing email id tags\n",
    "    text=re.sub('\\S*@\\S*\\s?',' ',text)\n",
    "    \n",
    "    # Removing url\n",
    "    text=re.sub(r'http\\S+', ' ',text)\n",
    "    \n",
    "    # removing r\\n\\ pattern\n",
    "    text=re.sub('[\\r\\n]+', ' ',text)\n",
    "    \n",
    "    # removing numbers and special characters\n",
    "    text=re.sub('[^A-Za-z ]+', ' ',text)\n",
    "    \n",
    "    # removing words beginning with capital letters\n",
    "    text= re.sub('([^.])( [A-Z]\\w*)', r'\\1',text)\n",
    "    \n",
    "    # Removing words less than lenghth 3\n",
    "    short = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "    text= short.sub(' ',text)\n",
    "    \n",
    "    # Converting to lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    # Lemmatize\n",
    "    lm = WordNetLemmatizer()\n",
    "    text= lm.lemmatize(text) \n",
    "    \n",
    "    # Stopwords removal\n",
    "    text = ' '.join([word for word in text.split() if word not in sw_spacy])\n",
    "\n",
    "    # Blank lines\n",
    "    text=re.sub(r'^$\\n', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # blank spaces\n",
    "    text=' '.join([line for line in text.split('\\n') if line.strip() != ''])\n",
    "    #text=' '.join()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c561ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text']= df['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c961f29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>shit bets clev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>gentlemen following champagne available approx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>sorry taken long trying fend chicks life soooo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abusive</td>\n",
       "      <td>asshole john cant gambling problem away bills ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class                                               Text\n",
       "0  Abusive                                     shit bets clev\n",
       "1  Abusive                                               fuck\n",
       "2  Abusive  gentlemen following champagne available approx...\n",
       "3  Abusive  sorry taken long trying fend chicks life soooo...\n",
       "4  Abusive  asshole john cant gambling problem away bills ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping content column\n",
    "df.drop('content',axis=1,inplace=True)\n",
    "df.rename(columns={'cleaned_text':'Text'},inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19592d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n"
     ]
    }
   ],
   "source": [
    "# Checking for empty strings\n",
    "count=0\n",
    "index=[]\n",
    "for i in range (len(df['Text'])):\n",
    "    if not(len(df['Text'][i].strip())):\n",
    "        index.append(i)\n",
    "        count=count+1\n",
    "print(count)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df794c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe after dropping empty strings: (24412, 2)\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows containing empty strings\n",
    "df.drop(index,inplace=True)\n",
    "\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "print('Shape of dataframe after dropping empty strings:',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4da53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.iloc[:,1]\n",
    "y= df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30369bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (17088,)\n",
      "Shape of testing data: (7324,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.3,stratify= y,random_state=1)\n",
    "\n",
    "print('Shape of training data:',(X_train.shape))\n",
    "print('Shape of testing data:',(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "533b54be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of y_train before resampling: Counter({'Non Abusive': 15941, 'Abusive': 1147})\n",
      "Distribution of y_train after resampling: Counter({'Non Abusive': 15941, 'Abusive': 15941})\n"
     ]
    }
   ],
   "source": [
    "print('Distribution of y_train before resampling:',Counter(y_train))\n",
    "\n",
    "# Converting X_train from series to 2D array\n",
    "X_train= X_train.values.reshape(-1,1)\n",
    "\n",
    "# Oversampling\n",
    "oversample = SMOTEN(sampling_strategy='minority')\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "print('Distribution of y_train after resampling:',Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "905d0a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abusive' 'Non Abusive']\n"
     ]
    }
   ],
   "source": [
    "## Label Encoding Y\n",
    "le= LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train= le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f35d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1= X_train.copy()\n",
    "X_test1= X_test.copy()\n",
    "y_train1= y_train.copy()\n",
    "y_test1= y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f0092fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 2D array to 1D array\n",
    "X_train1= X_train1.ravel()\n",
    "X_test1= X_test1.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d260aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf= TfidfVectorizer()\n",
    "\n",
    "tf.fit(X_train1)\n",
    "\n",
    "X_train1=tf.transform(X_train1)\n",
    "X_test1=tf.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bda07e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    0-Abusive       0.92      0.66      0.77       491\n",
      "1-Non Abusive       0.98      1.00      0.99      6833\n",
      "\n",
      "     accuracy                           0.97      7324\n",
      "    macro avg       0.95      0.83      0.88      7324\n",
      " weighted avg       0.97      0.97      0.97      7324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvc= LinearSVC()\n",
    "lsvc.fit(X_train1,y_train)\n",
    "\n",
    "lsvc_pred= lsvc.predict(X_test1)\n",
    "\n",
    "names=['0-Abusive','1-Non Abusive']\n",
    "print(classification_report(y_test, lsvc_pred,target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f5f1682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tf, open('final_vectorizer.pkl','wb'))\n",
    "pickle.dump(lsvc,open('final_lsvc_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67030b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
